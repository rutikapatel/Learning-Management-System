{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import sklearn.cluster\n",
    "import distance\n",
    "from boto3 import client\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List File names from s3 bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['David.txt',\n",
       " 'Diana.txt',\n",
       " 'Diane.txt',\n",
       " 'Jani.txt',\n",
       " 'Lore.txt',\n",
       " 'a.txt',\n",
       " 'algorithms.txt',\n",
       " 'appears.txt',\n",
       " 'exmaple.txt',\n",
       " 'following.txt',\n",
       " 'for.txt',\n",
       " 'list.txt',\n",
       " 'long.txt',\n",
       " 'problems.txt']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list=[]\n",
    "conn = client('s3')  # again assumes boto.cfg setup, assume AWS S3\n",
    "for key in conn.list_objects(Bucket='sagemaker-studio-qfizos0irmr')['Contents']:\n",
    "    file_list.append(key['Key'])\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract File name remove surfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['David',\n",
       " 'Diana',\n",
       " 'Diane',\n",
       " 'Jani',\n",
       " 'Lore',\n",
       " 'a',\n",
       " 'algorithms',\n",
       " 'appears',\n",
       " 'exmaple',\n",
       " 'following',\n",
       " 'for',\n",
       " 'list',\n",
       " 'long',\n",
       " 'problems']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names=[]\n",
    "for i in file_list:\n",
    "    new_i = '.'+i[len(i)-1]+i[len(i)-2]+i[len(i)-3]\n",
    "    i = i.replace(new_i,'')\n",
    "    file_names.append(i)\n",
    "file_names    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_words=['Christene Shanahan','Deanna Chrysler','Camille Selby','Viki Dennard','Thaddeus Burma','Idella Bartley','Kyung Evett']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adb-africa',\n",
       " 'adb-asia',\n",
       " 'aibd',\n",
       " 'aid',\n",
       " 'anrpc',\n",
       " 'asean',\n",
       " 'atpc',\n",
       " 'bis',\n",
       " 'cipec',\n",
       " 'comecon',\n",
       " 'ec',\n",
       " 'imf',\n",
       " 'inro',\n",
       " 'irsg',\n",
       " 'isa',\n",
       " 'itc',\n",
       " 'iwc-whale',\n",
       " 'mfa',\n",
       " 'oapec',\n",
       " 'oecd',\n",
       " 'opec',\n",
       " 'un',\n",
       " 'unctad',\n",
       " 'who',\n",
       " 'worldbank']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random=\"adb-africa adb-asia aibd aid anrpc asean atpc bis cipec comecon ec imf inro irsg isa itc iwc-whale mfa oapec oecd opec un unctad who worldbank\"\n",
    "random_list=[]\n",
    "for i in random.split():\n",
    "    random_list.append(i) \n",
    "random_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster File name using Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - adb-asia: adb-africa, adb-asia\n",
      " - aid: aibd, aid, bis, un\n",
      " - atpc: anrpc, atpc, itc\n",
      " - isa: asean, imf, inro, irsg, isa, mfa, who\n",
      " - iwc-whale: iwc-whale\n",
      " - opec: cipec, comecon, ec, oapec, oecd, opec\n",
      " - unctad: unctad\n",
      " - worldbank: worldbank\n"
     ]
    }
   ],
   "source": [
    "words = np.asarray(random_list) #So that indexing with a list will work\n",
    "lev_similarity = -1*np.array([[distance.levenshtein(w1,w2) for w1 in words] for w2 in words])\n",
    "affprop = sklearn.cluster.AffinityPropagation(affinity=\"precomputed\", damping=0.5)\n",
    "affprop.fit(lev_similarity)\n",
    "for cluster_id in np.unique(affprop.labels_):\n",
    "    exemplar = words[affprop.cluster_centers_indices_[cluster_id]]\n",
    "    cluster = np.unique(words[np.nonzero(affprop.labels_==cluster_id)])\n",
    "    cluster_str = \", \".join(cluster)\n",
    "    print(\" - %s: %s\" % (exemplar, cluster_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster File Using K-Means"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Learn from sklearn.cluster.KMeans https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TfidfVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7fa71da3f282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrue_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k-means++'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TfidfVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(file_names)\n",
    "\n",
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
